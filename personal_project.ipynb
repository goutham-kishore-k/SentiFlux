{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOz8sFQRnt9EVc0QrR6Hi97",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goutham-kishore-k/SentiFlux/blob/main/personal_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "o33aTfcaBlps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praw pymongo vaderSentiment yfinance asyncpraw googletrans gdeltdoc pytz #transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATOcv_0HuVzj",
        "outputId": "f6a95ac8-d161-4b3d-a033-c41219381802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.54)\n",
            "Collecting asyncpraw\n",
            "  Downloading asyncpraw-7.8.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting googletrans\n",
            "  Downloading googletrans-4.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gdeltdoc\n",
            "  Downloading gdeltdoc-1.5.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (2025.1)\n",
            "Collecting prawcore<3,>=2.4 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting update_checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Collecting aiofiles (from asyncpraw)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohttp<4 in /usr/local/lib/python3.11/dist-packages (from asyncpraw) (3.11.12)\n",
            "Collecting aiosqlite<=0.17.0 (from asyncpraw)\n",
            "  Downloading aiosqlite-0.17.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting asyncprawcore<3,>=2.4 (from asyncpraw)\n",
            "  Downloading asyncprawcore-2.4.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4->asyncpraw) (1.18.3)\n",
            "Requirement already satisfied: typing_extensions>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from aiosqlite<=0.17.0->asyncpraw) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
            "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncpraw-7.8.1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading googletrans-4.0.2-py3-none-any.whl (18 kB)\n",
            "Downloading gdeltdoc-1.5.0-py3-none-any.whl (13 kB)\n",
            "Downloading aiosqlite-0.17.0-py3-none-any.whl (15 kB)\n",
            "Downloading asyncprawcore-2.4.0-py3-none-any.whl (19 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: dnspython, aiosqlite, aiofiles, vaderSentiment, update_checker, pymongo, prawcore, praw, gdeltdoc, asyncprawcore, googletrans, asyncpraw\n",
            "Successfully installed aiofiles-24.1.0 aiosqlite-0.17.0 asyncpraw-7.8.1 asyncprawcore-2.4.0 dnspython-2.7.0 gdeltdoc-1.5.0 googletrans-4.0.2 praw-7.8.1 prawcore-2.4.0 pymongo-4.11.1 update_checker-0.18.0 vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import praw\n",
        "from pymongo import MongoClient\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import pytz\n",
        "from gdeltdoc import GdeltDoc, Filters\n",
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "'''\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "'''"
      ],
      "metadata": {
        "id": "J4Kymqny8eLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8a8200-2597-4c2f-c0c3-44b8919449c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom transformers import pipeline\\nfrom tqdm import tqdm\\nimport torch\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reddit API setup\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"KevGsI1SnGoLTev3AGQbXg\",\n",
        "    client_secret=\"L2mwvrE1VBOQL-2usCSlDBPs2yl2Og\",\n",
        "    user_agent=\"Tesla Sentiment Analysis\"\n",
        ")\n",
        "'''\n",
        "# MongoDB setup local\n",
        "client = MongoClient(\"mongodb://localhost:27017/\")\n",
        "db = client[\"reddit_tesla\"]\n",
        "posts_collection = db[\"posts\"]\n",
        "stock_collection = db[\"stock_data\"]\n",
        "sentiment_collection = db[\"sentiment_data\"]'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5skeDAh8kA-",
        "outputId": "7b5779f3-d738-4f87-e08e-67d81d6a5df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# MongoDB setup local\\nclient = MongoClient(\"mongodb://localhost:27017/\")\\ndb = client[\"reddit_tesla\"]\\nposts_collection = db[\"posts\"]\\nstock_collection = db[\"stock_data\"]\\nsentiment_collection = db[\"sentiment_data\"]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uri = \"mongodb+srv://gouthamkishorekrishnamoorthy:Nawoyr7RD3yEZJUn@cluster0.eibr0.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "db = client[\"reddit_tesla\"]\n",
        "posts_collection = db[\"posts\"]\n",
        "stock_collection = db[\"stock_data\"]\n",
        "sentiment_collection = db[\"post_sentiment_data\"]\n",
        "news_collection = db[\"gdelt_articles\"]\n",
        "news_sentiment = db[\"gdelt_sentiment\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHrcGTag9Dlx",
        "outputId": "92443b3f-d66d-4425-b8de-539a39db41a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinged your deployment. You successfully connected to MongoDB!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# control file\n"
      ],
      "metadata": {
        "id": "ddLGv6gvHiAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "control_doc = {\n",
        "    \"first_news_date\": None,\n",
        "    \"last_news_date\": None,\n",
        "    \"first_post_date\": None,\n",
        "    \"last_post_date\": None,\n",
        "    \"news_sentiment_until\": None,\n",
        "    \"post_sentiment_until\": None,\n",
        "    \"last_stock_fetch\": None\n",
        "}\n",
        "\n",
        "db.control.update_one({}, {\"$setOnInsert\": control_doc}, upsert=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzSaZcNQHm68",
        "outputId": "37dbcaee-e09f-4af6-9886-95e9a06b04a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UpdateResult({'n': 1, 'electionId': ObjectId('7fffffff0000000000000205'), 'opTime': {'ts': Timestamp(1740068785, 28), 't': 517}, 'nModified': 0, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1740068785, 28), 'signature': {'hash': b'\\xc1\\x88\\x15\\x1cv\\xe0\\x89I\\x16\\xdcA\\xea\\x820\\xa6\\xe9\\x96\\x975O', 'keyId': 7418413469524819988}}, 'operationTime': Timestamp(1740068785, 28), 'updatedExisting': True}, acknowledged=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first and last post dates control update\n",
        "result = list(db.posts.aggregate([\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": None,\n",
        "            \"first_post_date\": {\"$min\": \"$created_utc\"},\n",
        "            \"last_post_date\": {\"$max\": \"$created_utc\"}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$project\": {\n",
        "            \"_id\": 0,\n",
        "            \"first_post_date\": 1,\n",
        "            \"last_post_date\": 1\n",
        "        }\n",
        "    }\n",
        "]))\n",
        "\n",
        "if result:\n",
        "    # Convert UNIX timestamps to datetime objects\n",
        "    first_post_date = datetime.utcfromtimestamp(result[0]['first_post_date'])\n",
        "    last_post_date = datetime.utcfromtimestamp(result[0]['last_post_date'])\n",
        "\n",
        "    # Update the control document\n",
        "    db.control.update_one(\n",
        "        {},\n",
        "        {\n",
        "            \"$set\": {\n",
        "                \"first_post_date\": first_post_date,\n",
        "                \"last_post_date\": last_post_date\n",
        "            }\n",
        "        },\n",
        "        upsert=True\n",
        "    )\n",
        "    print(\"Control document updated successfully.\")\n",
        "else:\n",
        "    print(\"No posts found in the reddit_tesla collection.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD6ljbFrHtTg",
        "outputId": "ff23e057-de25-4421-dc8b-b3700307b14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control document updated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the stock_data collection for the earliest and latest dates\n",
        "result = list(db.stock_data.aggregate([\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": None,\n",
        "            \"first_stock_date\": {\"$min\": \"$date\"},\n",
        "            \"last_stock_date\": {\"$max\": \"$date\"}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$project\": {\n",
        "            \"_id\": 0,\n",
        "            \"first_stock_date\": 1,\n",
        "            \"last_stock_date\": 1\n",
        "        }\n",
        "    }\n",
        "]))\n",
        "\n",
        "if result:\n",
        "    # Convert date strings to datetime objects\n",
        "    first_stock_date = datetime.strptime(result[0]['first_stock_date'], \"%Y-%m-%d\")\n",
        "    last_stock_date = datetime.strptime(result[0]['last_stock_date'], \"%Y-%m-%d\")\n",
        "\n",
        "    # Update the control document\n",
        "    db.control.update_one(\n",
        "        {},\n",
        "        {\n",
        "            \"$set\": {\n",
        "                \"first_stock_date\": first_stock_date,\n",
        "                \"last_stock_date\": last_stock_date,\n",
        "                \"last_stock_fetch\": datetime.utcnow()  # Current time as the last fetch time\n",
        "            }\n",
        "        },\n",
        "        upsert=True\n",
        "    )\n",
        "    print(\"Control document updated successfully with stock data information.\")\n",
        "else:\n",
        "    print(\"No stock data found in the stock_data collection.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCTtd0I_TPAG",
        "outputId": "8a0955e7-6e8d-45b7-f299-c50c028f6732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control document updated successfully with stock data information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the gdelt_articles collection for the earliest and latest seendates\n",
        "result = list(db.gdelt_articles.aggregate([\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": None,\n",
        "            \"first_news_date\": {\"$min\": \"$seendate\"},\n",
        "            \"last_news_date\": {\"$max\": \"$seendate\"}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$project\": {\n",
        "            \"_id\": 0,\n",
        "            \"first_news_date\": 1,\n",
        "            \"last_news_date\": 1\n",
        "        }\n",
        "    }\n",
        "]))\n",
        "\n",
        "if result:\n",
        "    # Convert seendate strings to datetime objects\n",
        "    first_news_date = datetime.strptime(result[0]['first_news_date'], \"%Y%m%dT%H%M%SZ\")\n",
        "    last_news_date = datetime.strptime(result[0]['last_news_date'], \"%Y%m%dT%H%M%SZ\")\n",
        "\n",
        "    # Update the control document\n",
        "    update_result = db.control.update_one(\n",
        "        {},\n",
        "        {\n",
        "            \"$set\": {\n",
        "                \"first_news_date\": first_news_date,\n",
        "                \"last_news_date\": last_news_date\n",
        "            }\n",
        "        },\n",
        "        upsert=True\n",
        "    )\n",
        "\n",
        "    if update_result.modified_count > 0 or update_result.upserted_id:\n",
        "        print(\"Control document updated successfully.\")\n",
        "        print(f\"First news date: {first_news_date}\")\n",
        "        print(f\"Last news date: {last_news_date}\")\n",
        "    else:\n",
        "        print(\"No changes were made to the control document.\")\n",
        "else:\n",
        "    print(\"No news articles found in the gdelt_articles collection.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfZjyAo5WPoz",
        "outputId": "3186a99c-1574-424a-8aef-6b868ea4cdd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No changes were made to the control document.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the stock_data collection for the earliest and latest dates\n",
        "result = list(db.stock_data.aggregate([\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": None,\n",
        "            \"first_stock_date\": {\"$min\": \"$date\"},\n",
        "            \"last_stock_date\": {\"$max\": \"$date\"}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$project\": {\n",
        "            \"_id\": 0,\n",
        "            \"first_stock_date\": 1,\n",
        "            \"last_stock_date\": 1\n",
        "        }\n",
        "    }\n",
        "]))\n",
        "\n",
        "if result:\n",
        "    # Convert date strings to datetime objects\n",
        "    first_stock_date = datetime.strptime(result[0]['first_stock_date'], \"%Y-%m-%d\")\n",
        "    last_stock_date = datetime.strptime(result[0]['last_stock_date'], \"%Y-%m-%d\")\n",
        "\n",
        "    # Update the control document\n",
        "    db.control.update_one(\n",
        "        {},\n",
        "        {\n",
        "            \"$set\": {\n",
        "                \"first_stock_date\": first_stock_date,\n",
        "                \"last_stock_date\": last_stock_date,\n",
        "                \"last_stock_fetch\": datetime.utcnow()  # Current time as the last fetch time\n",
        "            }\n",
        "        },\n",
        "        upsert=True\n",
        "    )\n",
        "    print(\"Control document updated successfully with stock data information.\")\n",
        "else:\n",
        "    print(\"No stock data found in the stock_data collection.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6MFR6hXVxve",
        "outputId": "9b4c7440-b8ef-46d6-a165-3194b26a42e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control document updated successfully with stock data information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the aggregation pipeline\n",
        "pipeline = [\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": \"$date\",\n",
        "            \"avg_predicted_score\": { \"$avg\": \"$predicted_score\" },\n",
        "            \"avg_actual_sentiment\": { \"$avg\": \"$actual_sentiment\" }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$out\": \"gdelt_sentiment_data\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Execute the aggregation pipeline\n",
        "db.gdelt_sentiment.aggregate(pipeline)\n",
        "\n",
        "# Verify the results\n",
        "result_count = db.gdelt_sentiment_data.count_documents({})\n",
        "print(f\"Aggregated {result_count} documents in gdelt_sentiment_data collection.\")\n",
        "\n",
        "# Optional: Display a sample of the results\n",
        "sample = list(db.gdelt_sentiment_data.find().limit(5))\n",
        "for doc in sample:\n",
        "    print(f\"Date: {doc['_id']}, Avg Predicted Score: {doc['avg_predicted_score']:.4f}, Avg Actual Sentiment: {doc['avg_actual_sentiment']:.4f}\")\n",
        "\n",
        "# Update the control document with the latest processed date as post_sentiment_until\n",
        "latest_date = db.gdelt_sentiment_data.find_one(sort=[(\"_id\", -1)])\n",
        "if latest_date:\n",
        "    latest_date_obj = datetime.strptime(latest_date[\"_id\"], \"%Y%m%d\")\n",
        "    update_result = db.control.update_one(\n",
        "        {},\n",
        "        {\"$set\": {\"post_sentiment_until\": latest_date_obj}},\n",
        "        upsert=True\n",
        "    )\n",
        "    if update_result.modified_count > 0 or update_result.upserted_id:\n",
        "        print(f\"Updated control document with post_sentiment_until: {latest_date['_id']}\")\n",
        "    else:\n",
        "        print(\"No changes were made to the control document.\")\n",
        "else:\n",
        "    print(\"No data found in gdelt_sentiment_data collection.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNsGb3UJPCiz",
        "outputId": "d008a289-b66e-45f3-c7b6-8645cc3124ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated 31 documents in gdelt_sentiment_data collection.\n",
            "Date: 20250130, Avg Predicted Score: 0.9596, Avg Actual Sentiment: 0.0049\n",
            "Date: 20250116, Avg Predicted Score: 0.9748, Avg Actual Sentiment: -0.0104\n",
            "Date: 20250214, Avg Predicted Score: 0.9682, Avg Actual Sentiment: 0.1238\n",
            "Date: 20250203, Avg Predicted Score: 0.9409, Avg Actual Sentiment: -0.0971\n",
            "Date: 20250215, Avg Predicted Score: 0.9950, Avg Actual Sentiment: -0.4404\n",
            "No changes were made to the control document.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definitions"
      ],
      "metadata": {
        "id": "mbjXPen5Bv15"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reddit\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wlZztX_vyXE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_reddit_data(subreddit_name, keyword, days=365):\n",
        "    subreddit = reddit.subreddit(subreddit_name)\n",
        "    end_date = datetime.now(timezone.utc)\n",
        "    start_date = end_date - timedelta(days=days)\n",
        "\n",
        "    est_tz = pytz.timezone('US/Eastern')\n",
        "\n",
        "    after = None\n",
        "    while True:\n",
        "        submissions = subreddit.search(query=keyword, sort=\"new\", limit=100, params={\"after\": after})\n",
        "\n",
        "        batch_count = 0\n",
        "        for submission in submissions:\n",
        "            post_date_utc = datetime.fromtimestamp(submission.created_utc, tz=timezone.utc)\n",
        "            post_date_est = post_date_utc.astimezone(est_tz)\n",
        "\n",
        "            if post_date_utc < start_date:\n",
        "                return\n",
        "\n",
        "            post_data = {\n",
        "                \"id\": submission.id,\n",
        "                \"title\": submission.title,\n",
        "                'Author': submission.author.name if submission.author else 'Unknown',\n",
        "                \"selftext\": submission.selftext,\n",
        "                \"created_utc\": submission.created_utc,\n",
        "                \"created_est\": post_date_est.strftime(\"%Y-%m-%d %H:%M:%S %Z\"),\n",
        "                \"date\": post_date_est.strftime(\"%Y-%m-%d\"),\n",
        "                \"comments\": []\n",
        "            }\n",
        "\n",
        "            submission.comments.replace_more(limit=None)\n",
        "            for comment in submission.comments.list():\n",
        "                comment_date_utc = datetime.fromtimestamp(comment.created_utc, tz=timezone.utc)\n",
        "                comment_date_est = comment_date_utc.astimezone(est_tz)\n",
        "                post_data[\"comments\"].append({\n",
        "                    \"id\": comment.id,\n",
        "                    \"body\": comment.body,\n",
        "                    \"created_utc\": comment.created_utc,\n",
        "                    \"created_est\": comment_date_est.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
        "                })\n",
        "\n",
        "            posts_collection.update_one({\"id\": post_data[\"id\"]}, {\"$set\": post_data}, upsert=True)\n",
        "            batch_count += 1\n",
        "\n",
        "        print(f\"Fetched {batch_count} posts in this batch.\")\n",
        "\n",
        "        if batch_count == 0:\n",
        "            break\n",
        "        after = f\"t3_{submission.id}\"\n",
        "        time.sleep(2)"
      ],
      "metadata": {
        "id": "-xHIz9ez8ojp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stock"
      ],
      "metadata": {
        "id": "5uuEgJLBzFSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch Tesla stock data and store in MongoDB\n",
        "def fetch_stock_data():\n",
        "    tesla = yf.Ticker(\"TSLA\")\n",
        "    end_date = datetime.now(timezone.utc).strftime(\"%Y-%m-%d\")\n",
        "    start_date = (datetime.now(timezone.utc) - timedelta(days=365*10)).strftime(\"%Y-%m-%d\")\n",
        "    stock_data = tesla.history(start=start_date, end=end_date)\n",
        "\n",
        "    # Convert to UTC if it's not already\n",
        "    if stock_data.index.tzinfo != timezone.utc:\n",
        "        stock_data.index = stock_data.index.tz_convert('UTC')\n",
        "\n",
        "    stock_data.index = stock_data.index.strftime(\"%Y-%m-%d\")\n",
        "    stock_data = stock_data[[\"Open\", \"Close\"]]\n",
        "\n",
        "    for date, row in stock_data.iterrows():\n",
        "        stock_collection.update_one(\n",
        "            {\"date\": date},\n",
        "            {\"$set\": {\"open\": row[\"Open\"], \"close\": row[\"Close\"]}},\n",
        "            upsert=True\n",
        "        )\n",
        "\n",
        "    return stock_data"
      ],
      "metadata": {
        "id": "HelIqgCP8uZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reddit Sentiment"
      ],
      "metadata": {
        "id": "RzKkbrlSzLww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform sentiment analysis with time lag and store in MongoDB\n",
        "def perform_sentiment_analysis(lag_days=0):\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    results = {}\n",
        "    processed_ids = set()\n",
        "\n",
        "    for post in posts_collection.find():\n",
        "        if post[\"id\"] in processed_ids:\n",
        "            continue\n",
        "        processed_ids.add(post[\"id\"])\n",
        "\n",
        "        date = datetime.fromtimestamp(post[\"created_utc\"], tz=timezone.utc).strftime(\"%Y-%m-%d\")\n",
        "        text = post[\"title\"] + \" \" + post.get(\"selftext\", \"\")\n",
        "        sentiment = analyzer.polarity_scores(text)[\"compound\"]\n",
        "\n",
        "        for comment in post.get(\"comments\", []):\n",
        "            comment_sentiment = analyzer.polarity_scores(comment[\"body\"])[\"compound\"]\n",
        "            sentiment += comment_sentiment\n",
        "\n",
        "        avg_sentiment = sentiment / (len(post.get(\"comments\", [])) + 1)\n",
        "\n",
        "        if date in results:\n",
        "            results[date].append(avg_sentiment)\n",
        "        else:\n",
        "            results[date] = [avg_sentiment]\n",
        "\n",
        "    for date, sentiments in results.items():\n",
        "        avg_sentiment = sum(sentiments) / len(sentiments)\n",
        "        sentiment_date = datetime.strptime(date, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
        "        stock_date = (sentiment_date + timedelta(days=lag_days)).strftime(\"%Y-%m-%d\")\n",
        "        sentiment_collection.update_one(\n",
        "            {\"sentiment_date\": date, \"stock_date\": stock_date},\n",
        "            {\"$set\": {\"sentiment\": avg_sentiment}},\n",
        "            upsert=True\n",
        "        )\n",
        "\n",
        "    return results\n",
        "\n",
        "# Compare sentiment with stock movement\n",
        "def compare_sentiment_stock():\n",
        "    results = []\n",
        "\n",
        "    for sentiment_doc in sentiment_collection.find():\n",
        "        stock_date = sentiment_doc.get(\"stock_date\", sentiment_doc.get(\"sentiment_date\"))\n",
        "        stock_doc = stock_collection.find_one({\"date\": stock_date})\n",
        "\n",
        "        if stock_doc:\n",
        "            sentiment = sentiment_doc[\"sentiment\"]\n",
        "            stock_change = stock_doc[\"close\"] - stock_doc[\"open\"]\n",
        "            predicted_up = sentiment > 0\n",
        "            actual_up = stock_change > 0\n",
        "            correct_prediction = predicted_up == actual_up\n",
        "\n",
        "            results.append({\n",
        "                \"sentiment_date\": sentiment_doc.get(\"sentiment_date\"),\n",
        "                \"stock_date\": stock_date,\n",
        "                \"sentiment\": sentiment,\n",
        "                \"stock_change\": stock_change,\n",
        "                \"predicted_up\": predicted_up,\n",
        "                \"actual_up\": actual_up,\n",
        "                \"correct_prediction\": correct_prediction\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "hmaU_h2c8yXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Gdelt\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ok6AwY7ut1XW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GDELT setup\n",
        "gd = GdeltDoc()\n",
        "\n",
        "# Sentiment analyzer setup\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define EST timezone\n",
        "est_tz = pytz.timezone('US/Eastern')\n",
        "\n",
        "def fetch_and_store_gdelt_data(query, start_date, end_date, time_slice=timedelta(days=1)):\n",
        "    current_date = start_date\n",
        "    total_articles = 0\n",
        "\n",
        "    while current_date < end_date:\n",
        "        next_date = min(current_date + time_slice, end_date)\n",
        "\n",
        "        current_date_str = current_date.strftime(\"%Y-%m-%d\")\n",
        "        next_date_str = next_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        print(f\"Fetching data from {current_date_str} to {next_date_str}\")\n",
        "\n",
        "        try:\n",
        "            f = Filters(\n",
        "                keyword=query,\n",
        "                start_date=current_date_str,\n",
        "                end_date=next_date_str,\n",
        "            )\n",
        "            articles = gd.article_search(f)\n",
        "\n",
        "            if not articles.empty:\n",
        "                print(f\"Fetched {len(articles)} articles. Processing...\")\n",
        "                articles['sentiment'] = articles['title'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
        "                articles['ingestion_time'] = datetime.now(est_tz)\n",
        "\n",
        "                # Convert DataFrame to list of dictionaries\n",
        "                articles_dict = articles.to_dict('records')\n",
        "\n",
        "                # Insert into MongoDB\n",
        "                news_collection.insert_many(articles_dict)\n",
        "\n",
        "                total_articles += len(articles)\n",
        "            else:\n",
        "                print(\"No articles found for this time period.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing data: {e}\")\n",
        "\n",
        "        current_date = next_date\n",
        "        time.sleep(1)  # Add a small delay to avoid hitting rate limits\n",
        "\n",
        "    print(f\"Finished fetching and storing data. Total articles stored: {total_articles}\")"
      ],
      "metadata": {
        "id": "kbNnwYRIXSCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_gdelt_and_stock():\n",
        "    # Fetch GDELT data from MongoDB, filtering for English language and non-zero sentiment\n",
        "    gdelt_data = []\n",
        "    for article in news_collection.find({\"language\": \"English\", \"sentiment\": {\"$ne\": 0}}):\n",
        "        try:\n",
        "            date_str = article['seendate'][:8]  # Extract date part from seendate\n",
        "            date = datetime.strptime(date_str, '%Y%m%d').date()\n",
        "            sentiment = article['sentiment']\n",
        "            gdelt_data.append({'date': date, 'sentiment': sentiment})\n",
        "        except KeyError:\n",
        "            print(f\"Skipping article due to missing data: {article.get('_id')}\")\n",
        "\n",
        "    # Convert GDELT data to DataFrame and calculate daily average sentiment\n",
        "    gdelt_df = pd.DataFrame(gdelt_data)\n",
        "    if not gdelt_df.empty:\n",
        "        gdelt_df = gdelt_df.groupby('date')['sentiment'].mean().reset_index()\n",
        "        gdelt_df['date'] = pd.to_datetime(gdelt_df['date'])\n",
        "    else:\n",
        "        print(\"No English GDELT data found with non-zero sentiment.\")\n",
        "        return\n",
        "\n",
        "    # Fetch stock data (replace with actual stock data retrieval logic)\n",
        "    stock_df = pd.DataFrame(list(stock_collection.find({}, {\"_id\": 0, \"date\": 1, \"open\": 1, \"close\": 1})))\n",
        "    if not stock_df.empty:\n",
        "        stock_df['date'] = pd.to_datetime(stock_df['date'])\n",
        "        stock_df['stock_change'] = stock_df['close'] - stock_df['open']\n",
        "    else:\n",
        "        print(\"No Stock data found.\")\n",
        "        return\n",
        "\n",
        "    # Merge dataframes on date\n",
        "    merged_df = pd.merge(gdelt_df, stock_df, on='date', how='inner')\n",
        "\n",
        "    # Add predicted_up column\n",
        "    merged_df['predicted_up'] = merged_df['sentiment'] > merged_df['sentiment'].mean()\n",
        "\n",
        "    # Select and order columns\n",
        "    result_df = merged_df[['date', 'sentiment', 'open', 'close', 'stock_change', 'predicted_up']]\n",
        "\n",
        "    # Sort by date in descending order\n",
        "    result_df = result_df.sort_values('date', ascending=False)\n",
        "\n",
        "    # Display the result\n",
        "    print(result_df.to_string(index=True))\n",
        "\n",
        "    if not merged_df.empty:\n",
        "        correlation = merged_df['sentiment'].corr(merged_df['close'])\n",
        "        print(f\"Correlation between GDELT sentiment and stock price: {correlation}\")\n",
        "    else:\n",
        "        print(\"No overlapping dates between sentiment and stock data.\")\n",
        "\n",
        "# Example Usage\n",
        "#analyze_gdelt_and_stock()\n"
      ],
      "metadata": {
        "id": "94-iDNmFqg8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_gdelt_and_stock_return():\n",
        "    # Fetch GDELT data from MongoDB, filtering for English language and non-zero sentiment\n",
        "    gdelt_data = []\n",
        "    for article in news_collection.find({\"language\": \"English\", \"sentiment\": {\"$ne\": 0}}):\n",
        "        try:\n",
        "            date_str = article['seendate'][:8]  # Extract date part from seendate\n",
        "            date = datetime.strptime(date_str, '%Y%m%d').date()\n",
        "            sentiment = article['sentiment']\n",
        "            gdelt_data.append({'date': date, 'sentiment': sentiment})\n",
        "        except KeyError:\n",
        "            print(f\"Skipping article due to missing data: {article.get('_id')}\")\n",
        "\n",
        "    # Convert GDELT data to DataFrame and calculate daily average sentiment\n",
        "    gdelt_df = pd.DataFrame(gdelt_data)\n",
        "    if not gdelt_df.empty:\n",
        "        gdelt_df = gdelt_df.groupby('date')['sentiment'].mean().reset_index()\n",
        "        gdelt_df['date'] = pd.to_datetime(gdelt_df['date'])\n",
        "    else:\n",
        "        print(\"No English GDELT data found with non-zero sentiment.\")\n",
        "        return\n",
        "\n",
        "    # Fetch stock data\n",
        "    stock_df = pd.DataFrame(list(stock_collection.find({}, {\"_id\": 0, \"date\": 1, \"open\": 1, \"close\": 1})))\n",
        "    if not stock_df.empty:\n",
        "        stock_df['date'] = pd.to_datetime(stock_df['date'])\n",
        "        stock_df.set_index('date', inplace=True)\n",
        "        stock_df['next_day_close'] = stock_df['close'].shift(-1)\n",
        "        stock_df['stock_change'] = stock_df['next_day_close'] - stock_df['close']\n",
        "        stock_df['next_day_return'] = stock_df['stock_change'] / stock_df['close']\n",
        "    else:\n",
        "        print(\"No Stock data found.\")\n",
        "        return\n",
        "\n",
        "    # Merge dataframes, aligning today's sentiment with tomorrow's stock data\n",
        "    merged_df = pd.merge(gdelt_df, stock_df, left_on='date', right_index=True, how='inner')\n",
        "\n",
        "    # Add predicted_up column based on sentiment\n",
        "    merged_df['predicted_up'] = merged_df['sentiment'] > merged_df['sentiment'].mean()\n",
        "\n",
        "    # Select and order columns\n",
        "    result_df = merged_df[['date', 'sentiment', 'open', 'close', 'next_day_close', 'stock_change', 'next_day_return', 'predicted_up']]\n",
        "\n",
        "    # Sort by date in descending order\n",
        "    result_df = result_df.sort_values('date', ascending=False)\n",
        "\n",
        "    # Display the result\n",
        "    print(result_df.to_string(index=False))\n",
        "\n",
        "    if not merged_df.empty:\n",
        "        # Calculate correlations\n",
        "        sentiment_price_corr = merged_df['sentiment'].corr(merged_df['next_day_close'])\n",
        "        sentiment_return_corr = merged_df['sentiment'].corr(merged_df['next_day_return'])\n",
        "        print(f\"Correlation between today's GDELT sentiment and next day's stock price: {sentiment_price_corr:.4f}\")\n",
        "        print(f\"Correlation between today's GDELT sentiment and next day's stock return: {sentiment_return_corr:.4f}\")\n",
        "\n",
        "        # Calculate prediction accuracy\n",
        "        accuracy = (merged_df['predicted_up'] == (merged_df['stock_change'] > 0)).mean()\n",
        "        print(f\"Accuracy of predicting next day's price direction: {accuracy:.4f}\")\n",
        "    else:\n",
        "        print(\"No overlapping dates between sentiment and stock data.\")\n"
      ],
      "metadata": {
        "id": "k20kASmwrKE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the aggregation pipeline\n",
        "pipeline = [\n",
        "    {\n",
        "        \"$group\": {\n",
        "            \"_id\": \"$date\",\n",
        "            \"avg_predicted_score\": { \"$avg\": \"$predicted_score\" },\n",
        "            \"avg_actual_sentiment\": { \"$avg\": \"$actual_sentiment\" }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$out\": \"gdelt_sentiment_data\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Execute the aggregation pipeline\n",
        "db.gdelt_sentiment.aggregate(pipeline)\n",
        "\n",
        "# Verify the results\n",
        "result_count = db.gdelt_sentiment_data.count_documents({})\n",
        "print(f\"Aggregated {result_count} documents in gdelt_sentiment_data collection.\")\n",
        "\n",
        "# Optional: Display a sample of the results\n",
        "sample = list(db.gdelt_sentiment_data.find().limit(5))\n",
        "for doc in sample:\n",
        "    print(f\"Date: {doc['_id']}, Avg Predicted Score: {doc['avg_predicted_score']:.4f}, Avg Actual Sentiment: {doc['avg_actual_sentiment']:.4f}\")\n",
        "\n",
        "# Update the control document with the latest processed date\n",
        "latest_date = db.gdelt_sentiment_data.find_one(sort=[(\"_id\", -1)])\n",
        "if latest_date:\n",
        "    db.control.update_one(\n",
        "        {},\n",
        "        {\"$set\": {\"gdelt_sentiment_processed_until\": datetime.strptime(latest_date[\"_id\"], \"%Y%m%d\")}},\n",
        "        upsert=True\n",
        "    )\n",
        "    print(f\"Updated control document with latest processed date: {latest_date['_id']}\")\n",
        "else:\n",
        "    print(\"No data found in gdelt_sentiment_data collection.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1qSTjDjMq6e",
        "outputId": "86923532-8222-4be7-c908-0953475698b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated 31 documents in gdelt_sentiment_data collection.\n",
            "Date: 20250202, Avg Predicted Score: 0.9599, Avg Actual Sentiment: 0.1756\n",
            "Date: 20250209, Avg Predicted Score: 0.9424, Avg Actual Sentiment: -0.1898\n",
            "Date: 20250118, Avg Predicted Score: 0.9360, Avg Actual Sentiment: -0.0117\n",
            "Date: 20250116, Avg Predicted Score: 0.9748, Avg Actual Sentiment: -0.0104\n",
            "Date: 20250130, Avg Predicted Score: 0.9596, Avg Actual Sentiment: 0.0049\n",
            "Updated control document with latest processed date: 20250215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Executions"
      ],
      "metadata": {
        "id": "ZVAZclY9Bhaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reddit Fetch\n",
        "print(\"Fetching Reddit data...\")\n",
        "fetch_reddit_data(subreddit_name=\"all\", keyword=\"Tesla\")"
      ],
      "metadata": {
        "id": "k6ziRHx-15ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade yfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMR73OD0LZK1",
        "outputId": "c9b6e32d-5556-49cd-ff48-29971923ddd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.54)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stock fetch\n",
        "print(\"Fetching Tesla stock data...\")\n",
        "stock_data = fetch_stock_data()\n",
        "print(\"Stock data sample:\")\n",
        "print(stock_data.head())"
      ],
      "metadata": {
        "id": "IV778k3D15OH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4dfa313-eb03-4ec0-db33-efdce180b420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching Tesla stock data...\n",
            "Stock data sample:\n",
            "                 Open      Close\n",
            "Date                            \n",
            "2015-02-23  14.377333  13.822667\n",
            "2015-02-24  13.819333  13.607333\n",
            "2015-02-25  13.662667  13.584000\n",
            "2015-02-26  13.600000  13.812667\n",
            "2015-02-27  13.793333  13.556000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCdtgfYM8X_I",
        "outputId": "05b031d0-0879-4b5b-91a2-fe690fb26df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing sentiment analysis with 1-day lag...\n",
            "Comparing sentiment with stock data...\n",
            "Prediction Accuracy: 66.67%\n",
            "Sample of comparison data:\n",
            "  sentiment_date  stock_date  sentiment  stock_change  predicted_up  \\\n",
            "0     2025-02-14  2025-02-14   0.191755     -4.779999          True   \n",
            "1     2025-02-13  2025-02-13   0.251757     10.940002          True   \n",
            "2     2025-02-19  2025-02-19   0.241309      6.559998          True   \n",
            "\n",
            "   actual_up  correct_prediction  \n",
            "0      False               False  \n",
            "1       True                True  \n",
            "2       True                True  \n",
            "Analysis complete.\n"
          ]
        }
      ],
      "source": [
        "#post sentiment analysis\n",
        "print(\"Performing sentiment analysis with 1-day lag...\")\n",
        "sentiments = perform_sentiment_analysis(lag_days=0)\n",
        "print(\"Comparing sentiment with stock data...\")\n",
        "comparison_df = compare_sentiment_stock()\n",
        "if not comparison_df.empty:\n",
        "    accuracy = comparison_df[\"correct_prediction\"].mean()\n",
        "    print(f\"Prediction Accuracy: {accuracy:.2%}\")\n",
        "    print(\"Sample of comparison data:\")\n",
        "    print(comparison_df.head())\n",
        "else:\n",
        "    print(\"No matching dates between sentiments and stock data.\")\n",
        "print(\"Analysis complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gdelt Fetch\n",
        "query = [\"Tesla\", \"Elon Musk\", \"SpaceX\", \"EV\"]\n",
        "end_date = datetime.now(est_tz).replace(hour=0, minute=0, second=0, microsecond=0)\n",
        "start_date = end_date - timedelta(days=2)\n",
        "\n",
        "print(f\"Fetching data from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q41F-Ghiv_NL",
        "outputId": "419ab32f-afa9-4415-ba12-011ad6396c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data from 2025-02-17 to 2025-02-19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#News sentiment analysis\n",
        "analyze_gdelt_and_stock()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc7IUcUV0mXj",
        "outputId": "46be8444-da90-4229-9085-b768c896da7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         date  sentiment        open       close  stock_change  predicted_up\n",
            "20 2025-02-14   0.123769  360.619995  355.839996     -4.779999          True\n",
            "19 2025-02-13   0.077798  345.000000  355.940002     10.940002          True\n",
            "18 2025-02-12  -0.297260  329.940002  336.510010      6.570007         False\n",
            "17 2025-02-11  -0.100422  345.799988  328.500000    -17.299988         False\n",
            "16 2025-02-10  -0.091882  356.209991  350.730011     -5.479980         False\n",
            "15 2025-02-07   0.136644  370.190002  361.619995     -8.570007          True\n",
            "14 2025-02-06  -0.100840  373.029999  374.320007      1.290009         False\n",
            "13 2025-02-05  -0.091955  387.510010  378.170013     -9.339996         False\n",
            "12 2025-02-04  -0.103916  382.630005  392.209991      9.579987         False\n",
            "11 2025-02-03  -0.095947  386.679993  383.679993     -3.000000         False\n",
            "10 2025-01-31  -0.026995  401.529999  404.600006      3.070007          True\n",
            "9  2025-01-30   0.007177  410.779999  400.279999    -10.500000          True\n",
            "8  2025-01-29   0.099993  395.209991  389.100006     -6.109985          True\n",
            "7  2025-01-28  -0.275849  396.910004  398.089996      1.179993         False\n",
            "6  2025-01-27   0.044027  394.799988  397.149994      2.350006          True\n",
            "5  2025-01-24  -0.083795  414.450012  406.579987     -7.870026         False\n",
            "4  2025-01-23  -0.086386  416.059998  412.380005     -3.679993         False\n",
            "3  2025-01-22   0.028965  416.809998  415.109985     -1.700012          True\n",
            "2  2025-01-21   0.078289  432.640015  424.070007     -8.570007          True\n",
            "1  2025-01-17  -0.264777  421.500000  426.500000      5.000000         False\n",
            "0  2025-01-16  -0.010403  423.489990  413.820007     -9.669983          True\n",
            "Correlation between GDELT sentiment and stock price: 0.02277605020712167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archive"
      ],
      "metadata": {
        "id": "kkY-iOIY0pqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fail\n",
        "def analyze_gdelt_and_stock():\n",
        "    # Fetch GDELT data from MongoDB\n",
        "    gdelt_data = []\n",
        "    for article in news_collection.find():\n",
        "        try:\n",
        "            date_str = article['seendate'][:8]  # Extract date part from seendate\n",
        "            date = datetime.strptime(date_str, '%Y%m%d').date()\n",
        "            sentiment = article['sentiment']\n",
        "            gdelt_data.append({'date': date, 'sentiment': sentiment})\n",
        "        except KeyError:  # Handle articles missing 'seendate' or 'sentiment'\n",
        "            print(f\"Skipping article due to missing data: {article.get('_id')}\")\n",
        "\n",
        "    # Convert GDELT data to DataFrame and calculate daily average sentiment\n",
        "    gdelt_df = pd.DataFrame(gdelt_data)\n",
        "    if not gdelt_df.empty:\n",
        "        gdelt_df = gdelt_df.groupby('date')['sentiment'].mean().reset_index()\n",
        "        gdelt_df['date'] = pd.to_datetime(gdelt_df['date'])\n",
        "    else:\n",
        "        print(\"No GDELT data found.\")\n",
        "        return\n",
        "\n",
        "    # Fetch stock data (replace with actual stock data retrieval logic)\n",
        "    # Assuming stock_data is already a DataFrame with 'date' and 'close' columns\n",
        "    stock_df = pd.DataFrame(list(stock_collection.find({}, {\"_id\": 0, \"date\": 1, \"open\":1, \"close\": 1})))\n",
        "    if not stock_df.empty:\n",
        "        stock_df['date'] = pd.to_datetime(stock_df['date'])\n",
        "    else:\n",
        "        print(\"No Stock data found.\")\n",
        "        return\n",
        "\n",
        "    # Merge dataframes on date\n",
        "    merged_df = pd.merge(gdelt_df, stock_df, on='date', how='inner')\n",
        "\n",
        "    # Perform analysis (example: correlation between sentiment and stock price)\n",
        "    if not merged_df.empty:\n",
        "        correlation = merged_df['sentiment'].corr(merged_df['close'])\n",
        "        print(f\"Correlation between GDELT sentiment and stock price: {correlation}\")\n",
        "        print(merged_df)\n",
        "    else:\n",
        "        print(\"No overlapping dates between sentiment and stock data.\")\n",
        "\n",
        "# Example Usage\n",
        "analyze_gdelt_and_stock()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "0OVufzmGnUVl",
        "outputId": "6187cc94-bfbf-4eec-fd90-c80fa9baebeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'fail' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2a209c2c5223>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0manalyze_gdelt_and_stock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Fetch GDELT data from MongoDB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgdelt_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnews_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fail' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment_with_transformers(model_name, batch_size=32):\n",
        "    # Use CUDA if available\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    classifier = pipeline(\"sentiment-analysis\", model=model_name, device=device)\n",
        "    results = []\n",
        "\n",
        "    # Query for articles with non-zero sentiment\n",
        "    query = {\"sentiment\": {\"$ne\": 0}}\n",
        "    total_articles = collection.count_documents(query)\n",
        "\n",
        "    for batch in tqdm(collection.find(query).batch_size(batch_size), total=total_articles, desc=\"Processing articles\"):\n",
        "        title = batch.get('title', '')\n",
        "        if title:\n",
        "            sentiment = classifier(title)[0]\n",
        "            result = {\n",
        "                'title': title,\n",
        "                'predicted_label': sentiment['label'],\n",
        "                'predicted_score': sentiment['score'],\n",
        "                'actual_sentiment': batch.get('sentiment', 0),\n",
        "                'date': batch.get('seendate', '')[:8]\n",
        "            }\n",
        "            results.append(result)\n",
        "            collection.update_one({'_id': batch['_id']}, {'$set': result}, upsert=True)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Example usage\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "sentiment_df = analyze_sentiment_with_transformers(model_name)\n",
        "\n",
        "# Compare predicted sentiment with actual sentiment\n",
        "sentiment_df['sentiment_match'] = (sentiment_df['predicted_label'] == 'POSITIVE') == (sentiment_df['actual_sentiment'] > 0)\n",
        "accuracy = sentiment_df['sentiment_match'].mean()\n",
        "\n",
        "print(f\"Model accuracy: {accuracy:.2f}\")\n",
        "print(sentiment_df[['predicted_label', 'actual_sentiment', 'sentiment_match']].head())\n"
      ],
      "metadata": {
        "id": "adrZICjI2YlY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "bda42a78-c6cf-4725-ef2c-4dc5db016db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-536bb9be48b5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"distilbert-base-uncased-finetuned-sst-2-english\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0msentiment_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_sentiment_with_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Compare predicted sentiment with actual sentiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-536bb9be48b5>\u001b[0m in \u001b[0;36manalyze_sentiment_with_transformers\u001b[0;34m(model_name, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0manalyze_sentiment_with_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Use CUDA if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentiment-analysis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#collection = db[\"gdelt_sentiment\"]\n",
        "\n",
        "# Convert DataFrame to a list of dictionaries\n",
        "sentiment_data = sentiment_df.to_dict('records')\n",
        "\n",
        "# Insert the data into the collection\n",
        "news_sentiment.insert_many(sentiment_data)\n",
        "print(f\"Successfully stored sentiment data in MongoDB collection '{news_sentiment}'.\")"
      ],
      "metadata": {
        "id": "PwX_AWvK5X8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: {\n",
        "#   \"_id\": {\n",
        "#     \"$oid\": \"67b05c323d13fa1a7c7d4c58\"\n",
        "#   },\n",
        "#   \"title\": \"Small British satellite specialist sees shares rocket on deal with Elon Musk SpaceX\",\n",
        "#   \"predicted_label\": \"POSITIVE\",\n",
        "#   \"predicted_score\": 0.8226331472396851,\n",
        "#   \"actual_sentiment\": 0.296,\n",
        "#   \"date\": \"20250210\",\n",
        "#   \"sentiment_match\": true\n",
        "# }\n",
        "# get the avg sentiment by date and compare it with stock data and give predected up and actual up\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def analyze_sentiment_by_date(news_collection):\n",
        "    \"\"\"\n",
        "    Analyzes sentiment data by date, compares it with stock data, and determines prediction accuracy.\n",
        "    \"\"\"\n",
        "    sentiment_data = []\n",
        "    for item in collection.find():\n",
        "        try:\n",
        "            sentiment_data.append({\n",
        "                'date': item['date'],\n",
        "                'predicted_label': item['predicted_label'],\n",
        "                'predicted_score': item['predicted_score'],\n",
        "                'actual_sentiment': item['actual_sentiment']\n",
        "            })\n",
        "        except KeyError as e:\n",
        "            print(f\"Skipping item due to missing key: {e}\")\n",
        "\n",
        "    sentiment_df = pd.DataFrame(sentiment_data)\n",
        "\n",
        "    if not sentiment_df.empty:\n",
        "        # Group by date and calculate average sentiment\n",
        "        daily_sentiment = sentiment_df.groupby('date').agg({\n",
        "            'predicted_score': 'mean',\n",
        "            'actual_sentiment': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        # Assuming 'stock_collection' exists with 'date', 'open', and 'close'\n",
        "        stock_data = list(stock_collection.find({}, {\"_id\": 0, \"date\": 1, \"open\": 1, \"close\": 1}))\n",
        "        stock_df = pd.DataFrame(stock_data)\n",
        "        if not stock_df.empty:\n",
        "          stock_df['date'] = pd.to_datetime(stock_df['date'])\n",
        "          daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])\n",
        "          merged_df = pd.merge(daily_sentiment, stock_df, on='date', how='left')\n",
        "\n",
        "          # Calculate stock price change\n",
        "          merged_df['stock_change'] = merged_df['close'] - merged_df['open']\n",
        "          merged_df['predicted_up'] = merged_df['predicted_score'] > 0.5 # adjust threshold as needed\n",
        "          merged_df['actual_up'] = merged_df['stock_change'] > 0\n",
        "\n",
        "          # Calculate prediction accuracy\n",
        "          merged_df['correct_prediction'] = merged_df['predicted_up'] == merged_df['actual_up']\n",
        "          accuracy = merged_df['correct_prediction'].mean()\n",
        "\n",
        "          print(f\"Prediction Accuracy: {accuracy:.2f}\")\n",
        "          print(merged_df)\n",
        "\n",
        "        else:\n",
        "            print(\"No stock data found for comparison.\")\n",
        "\n",
        "    else:\n",
        "        print(\"No sentiment data found for analysis.\")\n",
        "\n",
        "\n",
        "# Example usage (assuming you have a 'collection' object)\n",
        "analyze_sentiment_by_date(news_collection)\n"
      ],
      "metadata": {
        "id": "TirTv_yu6aqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "\n",
        "def analyze_sentiment_with_transformers(model_name, batch_size=32):\n",
        "    classifier = pipeline(\"sentiment-analysis\", model=model_name, device=\"cpu\")  # Use CPU for compatibility\n",
        "    results = []\n",
        "\n",
        "    # Filter for English articles with non-zero sentiment\n",
        "    query = {\"language\": \"English\", \"sentiment\": {\"$ne\": 0}}\n",
        "    total_articles = collection.count_documents(query)\n",
        "\n",
        "    # Batch processing\n",
        "    for batch in tqdm(collection.find(query).batch_size(batch_size), total=total_articles, desc=\"Processing articles\"):\n",
        "        if isinstance(batch, dict):\n",
        "            title = batch.get('title', '')\n",
        "            date = batch.get('seendate', '')[:8]\n",
        "        elif isinstance(batch, str):\n",
        "            title = batch\n",
        "            date = ''\n",
        "        else:\n",
        "            print(f\"Unexpected type for batch: {type(batch)}\")\n",
        "            continue\n",
        "\n",
        "        if title:\n",
        "            sentiment = classifier(title)[0]\n",
        "            results.append({\n",
        "                'title': title,\n",
        "                'label': sentiment['label'],\n",
        "                'score': sentiment['score'],\n",
        "                'date': date\n",
        "            })\n",
        "        else:\n",
        "            print(f\"Skipping article due to empty title\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Example usage:\n",
        "model_names = [\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "               \"bert-base-uncased-finetuned-sst-2-english\"]\n",
        "\n",
        "for model_name in model_names:\n",
        "    print(f\"Analyzing sentiments with {model_name}:\")\n",
        "    try:\n",
        "        sentiment_df = analyze_sentiment_with_transformers(model_name)\n",
        "\n",
        "        if not sentiment_df.empty:\n",
        "            # Display summary statistics\n",
        "            print(sentiment_df.describe())\n",
        "\n",
        "            # Calculate average sentiment score\n",
        "            avg_sentiment = sentiment_df['score'].mean()\n",
        "            print(f\"Average sentiment score: {avg_sentiment:.4f}\")\n",
        "\n",
        "            # Count of positive vs negative sentiments\n",
        "            sentiment_counts = sentiment_df['label'].value_counts()\n",
        "            print(\"Sentiment distribution:\")\n",
        "            print(sentiment_counts)\n",
        "        else:\n",
        "            print(\"No data to analyze after filtering.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing {model_name}: {str(e)}\")\n",
        "\n",
        "    print(\"-\" * 40)  # Separator between results of different models\n"
      ],
      "metadata": {
        "id": "Vv8hp4MFtfXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch Reddit data and store in MongoDB\n",
        "def fetch_reddit_data1(subreddit_name, keyword, days=365):\n",
        "    subreddit = reddit.subreddit(subreddit_name)\n",
        "    end_date = datetime.now(timezone.utc)\n",
        "    start_date = end_date - timedelta(days=days)\n",
        "\n",
        "    after = None\n",
        "    while True:\n",
        "        submissions = subreddit.search(query=keyword, sort=\"new\", limit=100, params={\"after\": after})\n",
        "\n",
        "        batch_count = 0\n",
        "        for submission in submissions:\n",
        "            post_date = datetime.fromtimestamp(submission.created_utc, tz=timezone.utc)\n",
        "            if post_date < start_date:\n",
        "                return\n",
        "\n",
        "            post_data = {\n",
        "                \"id\": submission.id,\n",
        "                \"title\": submission.title,\n",
        "                'Author': submission.author.name if submission.author else 'Unknown',\n",
        "                \"selftext\": submission.selftext,\n",
        "                \"created_utc\": submission.created_utc,\n",
        "                \"date\": post_date.strftime(\"%Y-%m-%d\"),\n",
        "                \"comments\": []\n",
        "            }\n",
        "\n",
        "            submission.comments.replace_more(limit=None)\n",
        "            for comment in submission.comments.list():\n",
        "                post_data[\"comments\"].append({\n",
        "                    \"id\": comment.id,\n",
        "                    \"body\": comment.body,\n",
        "                    \"created_utc\": comment.created_utc\n",
        "                })\n",
        "\n",
        "            posts_collection.update_one({\"id\": post_data[\"id\"]}, {\"$set\": post_data}, upsert=True)\n",
        "            batch_count += 1\n",
        "\n",
        "        print(f\"Fetched {batch_count} posts in this batch.\")\n",
        "\n",
        "        if batch_count == 0:\n",
        "            break\n",
        "        after = f\"t3_{submission.id}\"\n",
        "        time.sleep(2)"
      ],
      "metadata": {
        "id": "5yRxGP9v8r7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Currently working"
      ],
      "metadata": {
        "id": "Tom3MxIIexd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AlphaVantage\n"
      ],
      "metadata": {
        "id": "4NMYjOBJe6Yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from pymongo import MongoClient\n",
        "\n",
        "def fetch_stock_data():\n",
        "    tesla = yf.Ticker(\"TSLA\")\n",
        "    end_date = datetime.now(timezone.utc).strftime(\"%Y-%m-%d\")\n",
        "    start_date = (datetime.now(timezone.utc) - timedelta(days=365*10)).strftime(\"%Y-%m-%d\")\n",
        "    stock_data = tesla.history(start=start_date, end=end_date)\n",
        "\n",
        "    # Convert to UTC if it's not already\n",
        "    if stock_data.index.tzinfo != timezone.utc:\n",
        "        stock_data.index = stock_data.index.tz_convert('UTC')\n",
        "\n",
        "    stock_data.index = stock_data.index.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # Check if 'Adj Close' is available, if not use 'Close'\n",
        "    columns = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
        "    if \"Adj Close\" in stock_data.columns:\n",
        "        columns.append(\"Adj Close\")\n",
        "    else:\n",
        "        print(\"Warning: 'Adj Close' not available. Using 'Close' instead.\")\n",
        "\n",
        "    stock_data = stock_data[columns]\n",
        "\n",
        "    # Assuming you have already set up a MongoDB connection and collection\n",
        "    for date, row in stock_data.iterrows():\n",
        "        update_data = {\n",
        "            \"open\": row[\"Open\"],\n",
        "            \"high\": row[\"High\"],\n",
        "            \"low\": row[\"Low\"],\n",
        "            \"close\": row[\"Close\"],\n",
        "            \"volume\": row[\"Volume\"]\n",
        "        }\n",
        "        if \"Adj Close\" in row:\n",
        "            update_data[\"adjusted_close\"] = row[\"Adj Close\"]\n",
        "        else:\n",
        "            update_data[\"adjusted_close\"] = row[\"Close\"]\n",
        "\n",
        "        stock_collection.update_one(\n",
        "            {\"date\": date},\n",
        "            {\"$set\": update_data},\n",
        "            upsert=True\n",
        "        )\n",
        "\n",
        "    return stock_data\n",
        "\n",
        "\n",
        "# Stock fetch\n",
        "print(\"Fetching Tesla stock data...\")\n",
        "stock_data = fetch_stock_data()\n",
        "print(\"Stock data sample:\")\n",
        "print(stock_data.head())\n"
      ],
      "metadata": {
        "id": "_CLtUHASe-rk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afdf8399-af12-4983-8ee4-13825bbb2b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching Tesla stock data...\n",
            "Warning: 'Adj Close' not available. Using 'Close' instead.\n",
            "Stock data sample:\n",
            "                 Open       High        Low      Close     Volume\n",
            "Date                                                             \n",
            "2015-03-02  13.513333  13.556000  13.055333  13.155333  118831500\n",
            "2015-03-03  13.120667  13.349333  13.021333  13.304000   66484500\n",
            "2015-03-04  13.283333  13.501333  13.147333  13.496000   63330000\n",
            "2015-03-05  13.523333  13.746000  13.343333  13.375333   73155000\n",
            "2015-03-06  13.280667  13.383333  12.810000  12.925333  100686000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "_jdm34aY5GFn",
        "outputId": "0f00bbb7-0b1e-4735-a14e-3024b6751890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Open       High        Low      Close     Volume\n",
              "Date                                                             \n",
              "2015-03-02  13.513333  13.556000  13.055333  13.155333  118831500\n",
              "2015-03-03  13.120667  13.349333  13.021333  13.304000   66484500\n",
              "2015-03-04  13.283333  13.501333  13.147333  13.496000   63330000\n",
              "2015-03-05  13.523333  13.746000  13.343333  13.375333   73155000\n",
              "2015-03-06  13.280667  13.383333  12.810000  12.925333  100686000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88e2a116-ca97-4330-91ff-33df954558fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-03-02</th>\n",
              "      <td>13.513333</td>\n",
              "      <td>13.556000</td>\n",
              "      <td>13.055333</td>\n",
              "      <td>13.155333</td>\n",
              "      <td>118831500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-03</th>\n",
              "      <td>13.120667</td>\n",
              "      <td>13.349333</td>\n",
              "      <td>13.021333</td>\n",
              "      <td>13.304000</td>\n",
              "      <td>66484500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-04</th>\n",
              "      <td>13.283333</td>\n",
              "      <td>13.501333</td>\n",
              "      <td>13.147333</td>\n",
              "      <td>13.496000</td>\n",
              "      <td>63330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-05</th>\n",
              "      <td>13.523333</td>\n",
              "      <td>13.746000</td>\n",
              "      <td>13.343333</td>\n",
              "      <td>13.375333</td>\n",
              "      <td>73155000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-06</th>\n",
              "      <td>13.280667</td>\n",
              "      <td>13.383333</td>\n",
              "      <td>12.810000</td>\n",
              "      <td>12.925333</td>\n",
              "      <td>100686000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88e2a116-ca97-4330-91ff-33df954558fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88e2a116-ca97-4330-91ff-33df954558fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88e2a116-ca97-4330-91ff-33df954558fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-272d1b52-b058-483c-96d2-bd76fe4fc1d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-272d1b52-b058-483c-96d2-bd76fe4fc1d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-272d1b52-b058-483c-96d2-bd76fe4fc1d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stock_data",
              "summary": "{\n  \"name\": \"stock_data\",\n  \"rows\": 2513,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2513,\n        \"samples\": [\n          \"2017-12-07\",\n          \"2016-11-15\",\n          \"2019-05-31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 118.06563958604657,\n        \"min\": 9.48799991607666,\n        \"max\": 475.8999938964844,\n        \"num_unique_values\": 2401,\n        \"samples\": [\n          23.293333053588867,\n          15.876667022705078,\n          226.58999633789062\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 120.70467213120305,\n        \"min\": 10.33133316040039,\n        \"max\": 488.5400085449219,\n        \"num_unique_values\": 2400,\n        \"samples\": [\n          239.0,\n          203.9499969482422,\n          20.398666381835938\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115.10681693851487,\n        \"min\": 9.403332710266113,\n        \"max\": 457.510009765625,\n        \"num_unique_values\": 2422,\n        \"samples\": [\n          23.972667694091797,\n          66.267333984375,\n          22.476667404174805\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 117.9169170464496,\n        \"min\": 9.57800006866455,\n        \"max\": 479.8599853515625,\n        \"num_unique_values\": 2462,\n        \"samples\": [\n          21.34000015258789,\n          259.1866760253906,\n          19.46466636657715\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 73979514,\n        \"min\": 10620000,\n        \"max\": 914082000,\n        \"num_unique_values\": 2503,\n        \"samples\": [\n          73848000,\n          139809000,\n          56376000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tesla = yf.Ticker(\"TSLA\")\n",
        "end_date = datetime.now(timezone.utc).strftime(\"%Y-%m-%d\")\n",
        "start_date = (datetime.now(timezone.utc) - timedelta(days=10)).strftime(\"%Y-%m-%d\")\n",
        "stock_data = tesla.history(start=start_date, end=end_date)\n",
        "stock_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "QARRXTUi5IuK",
        "outputId": "9701bde5-1364-4f52-9094-60c04aabe2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 Open        High         Low       Close  \\\n",
              "Date                                                                        \n",
              "2025-02-18 00:00:00-05:00  355.010010  359.100006  350.019989  354.109985   \n",
              "2025-02-19 00:00:00-05:00  354.000000  367.339996  353.670013  360.559998   \n",
              "2025-02-20 00:00:00-05:00  361.510010  362.299988  348.000000  354.399994   \n",
              "2025-02-21 00:00:00-05:00  353.440002  354.980011  334.420013  337.799988   \n",
              "2025-02-24 00:00:00-05:00  338.140015  342.399994  324.700012  330.529999   \n",
              "\n",
              "                             Volume  Dividends  Stock Splits  \n",
              "Date                                                          \n",
              "2025-02-18 00:00:00-05:00  51631700        0.0           0.0  \n",
              "2025-02-19 00:00:00-05:00  67094400        0.0           0.0  \n",
              "2025-02-20 00:00:00-05:00  45965400        0.0           0.0  \n",
              "2025-02-21 00:00:00-05:00  74058600        0.0           0.0  \n",
              "2025-02-24 00:00:00-05:00  76052300        0.0           0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-292fbbe6-9638-4cc8-92fd-287179d19474\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-02-18 00:00:00-05:00</th>\n",
              "      <td>355.010010</td>\n",
              "      <td>359.100006</td>\n",
              "      <td>350.019989</td>\n",
              "      <td>354.109985</td>\n",
              "      <td>51631700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-02-19 00:00:00-05:00</th>\n",
              "      <td>354.000000</td>\n",
              "      <td>367.339996</td>\n",
              "      <td>353.670013</td>\n",
              "      <td>360.559998</td>\n",
              "      <td>67094400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-02-20 00:00:00-05:00</th>\n",
              "      <td>361.510010</td>\n",
              "      <td>362.299988</td>\n",
              "      <td>348.000000</td>\n",
              "      <td>354.399994</td>\n",
              "      <td>45965400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-02-21 00:00:00-05:00</th>\n",
              "      <td>353.440002</td>\n",
              "      <td>354.980011</td>\n",
              "      <td>334.420013</td>\n",
              "      <td>337.799988</td>\n",
              "      <td>74058600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-02-24 00:00:00-05:00</th>\n",
              "      <td>338.140015</td>\n",
              "      <td>342.399994</td>\n",
              "      <td>324.700012</td>\n",
              "      <td>330.529999</td>\n",
              "      <td>76052300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-292fbbe6-9638-4cc8-92fd-287179d19474')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-292fbbe6-9638-4cc8-92fd-287179d19474 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-292fbbe6-9638-4cc8-92fd-287179d19474');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-42ee68b3-56d7-4d66-a807-ed0311d6e5b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42ee68b3-56d7-4d66-a807-ed0311d6e5b9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-42ee68b3-56d7-4d66-a807-ed0311d6e5b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stock_data",
              "summary": "{\n  \"name\": \"stock_data\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-02-18 00:00:00-05:00\",\n        \"max\": \"2025-02-25 00:00:00-05:00\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"2025-02-18 00:00:00-05:00\",\n          \"2025-02-19 00:00:00-05:00\",\n          \"2025-02-25 00:00:00-05:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.918400235527105,\n        \"min\": 327.0199890136719,\n        \"max\": 361.510009765625,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          355.010009765625,\n          354.0,\n          327.0199890136719\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.320735330299973,\n        \"min\": 328.8900146484375,\n        \"max\": 367.3399963378906,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          359.1000061035156,\n          367.3399963378906,\n          328.8900146484375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.326185105691295,\n        \"min\": 297.25,\n        \"max\": 353.6700134277344,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          350.0199890136719,\n          353.6700134277344,\n          297.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.48264523782907,\n        \"min\": 302.79998779296875,\n        \"max\": 360.55999755859375,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          354.1099853515625,\n          360.55999755859375,\n          302.79998779296875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31500704,\n        \"min\": 45965400,\n        \"max\": 134228800,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          51631700,\n          67094400,\n          134228800\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dividends\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stock Splits\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pymongo import MongoClient\n",
        "from datetime import datetime, timezone, timedelta\n",
        "import pandas as pd\n",
        "\n",
        "# Alpha Vantage API Key - Replace with your actual API key\n",
        "ALPHA_VANTAGE_API_KEY = \"TMXI2XR66IEWAEG5\"  # Replace with your key!\n",
        "STOCK_SYMBOL = \"TSLA\"\n",
        "COLLECTION_NAME = \"tesla_stock\"\n",
        "\n",
        "\n",
        "def fetch_stock_data_alphavantage(api_key, symbol):\n",
        "    \"\"\"Fetches full stock data from Alpha Vantage API.\"\"\"\n",
        "    url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={symbol}&outputsize=full&apikey={api_key}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if \"Time Series (Daily)\" in data:\n",
        "            stock_data = pd.DataFrame.from_dict(data[\"Time Series (Daily)\"], orient=\"index\")\n",
        "            stock_data = stock_data.astype(float)\n",
        "            stock_data.index = pd.to_datetime(stock_data.index)\n",
        "            stock_data = stock_data.rename(columns={\n",
        "                \"1. open\": \"open\",\n",
        "                \"2. high\": \"high\",\n",
        "                \"3. low\": \"low\",\n",
        "                \"4. close\": \"close\",\n",
        "                \"5. adjusted close\": \"adjusted_close\",\n",
        "                \"6. volume\": \"volume\",\n",
        "                \"7. dividend amount\": \"dividend_amount\",\n",
        "                \"8. split coefficient\": \"split_coefficient\"\n",
        "            })\n",
        "            return stock_data\n",
        "        elif \"Error Message\" in data:\n",
        "            print(f\"Error from Alpha Vantage: {data['Error Message']}\")\n",
        "        else:\n",
        "            print(f\"Unexpected response from Alpha Vantage: {data}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request error: {e}\")\n",
        "    except ValueError as e:\n",
        "        print(f\"JSON decoding error: {e}\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Key error: {e}\")\n",
        "    return None\n",
        "\n",
        "def ingest_data_to_mongodb(stock_data, symbol, mongo_uri, database_name, collection_name):\n",
        "    \"\"\"Ingests full stock data into MongoDB.\"\"\"\n",
        "    try:\n",
        "        client = MongoClient(mongo_uri)\n",
        "        db = client[database_name]\n",
        "        collection = db[collection_name]\n",
        "\n",
        "        # Create a compound index on symbol and date\n",
        "        collection.create_index([(\"symbol\", ASCENDING), (\"date\", ASCENDING)], unique=True)\n",
        "\n",
        "        for date, row in stock_data.iterrows():\n",
        "            document = {\n",
        "                \"symbol\": symbol,\n",
        "                \"date\": date.to_pydatetime(),\n",
        "                \"open\": row[\"open\"],\n",
        "                \"high\": row[\"high\"],\n",
        "                \"low\": row[\"low\"],\n",
        "                \"close\": row[\"close\"],\n",
        "                \"adjusted_close\": row[\"adjusted_close\"],\n",
        "                \"volume\": row[\"volume\"],\n",
        "                \"dividend_amount\": row[\"dividend_amount\"],\n",
        "                \"split_coefficient\": row[\"split_coefficient\"]\n",
        "            }\n",
        "            collection.update_one(\n",
        "                {\"symbol\": symbol, \"date\": date.to_pydatetime()},\n",
        "                {\"$set\": document},\n",
        "                upsert=True\n",
        "            )\n",
        "        print(f\"Successfully ingested data for {symbol} into MongoDB collection '{collection_name}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error ingesting data to MongoDB: {e}\")\n",
        "    finally:\n",
        "        client.close()\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to fetch data and ingest into MongoDB.\"\"\"\n",
        "    stock_data = fetch_stock_data_alphavantage(ALPHA_VANTAGE_API_KEY, STOCK_SYMBOL)\n",
        "    if stock_data is not None:\n",
        "        ingest_data_to_mongodb(stock_data, STOCK_SYMBOL, MONGO_URI, DATABASE_NAME, COLLECTION_NAME)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02gt2eV8DDen",
        "outputId": "454ff463-bbc0-4b0d-98dc-9184e8f78779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unexpected response from Alpha Vantage: {'Information': 'Thank you for using Alpha Vantage! This is a premium endpoint. You may subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly unlock all premium endpoints'}\n"
          ]
        }
      ]
    }
  ]
}